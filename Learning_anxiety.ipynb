{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM0gT5JeXOdNENLebHZTDFx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sudhandra/Learning_Anxiety-/blob/main/Learning_anxiety.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#colab without interruption : ctrl_shft+i\n",
        "function ClickConnect()\n",
        "{\n",
        "console.log(\"Working\");\n",
        "document.querySelector(\"colab-toolbar-button\").click()\n",
        "}\n",
        "setInterval(ClickConnect,60000)"
      ],
      "metadata": {
        "id": "ymE2aQmO-NZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "a = []\n",
        "while(1):\n",
        "  a.append('1')"
      ],
      "metadata": {
        "id": "EsCvNfrI-kwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKsUhqkCom9K"
      },
      "outputs": [],
      "source": [
        "#package\n",
        "!pip3 install Torch\n",
        "!pip3 install detecto\n",
        "!pip install utils\n",
        "#libraries\n",
        "from detecto import core, utils, visualize\n",
        "from detecto.utils import read_image\n",
        "from detecto.core import Dataset\n",
        "from detecto.utils import xml_to_csv\n",
        "from detecto.visualize import show_labeled_image\n",
        "from detecto.core import DataLoader, Model\n",
        "from detecto.visualize import show_labeled_image, plot_prediction_grid\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "# Import the 'utils' module\n",
        "import utils as utils\n",
        "import sys\n",
        "import torch\n",
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset path\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "os.chdir(r'/content/gdrive/My Drive/Emotion Intelligence/Model_20/')\n",
        "!ls '/content/gdrive/My Drive/Emotion Intelligence/Model_20/'"
      ],
      "metadata": {
        "id": "7VEmUTOMotyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Show Image\n",
        "image = read_image('Age_16.1.jpg')\n",
        "plt.imshow(image)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "s0fDAxKnif7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import utils as utils\n",
        "import sys\n",
        "# Add the directory containing the 'utils' module to the system path\n",
        "sys.path.append('/path/to/utils/module/directory')\n",
        "# Import the 'utils' module\n",
        "#import utils as utils\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "from detecto import core, utils, visualize\n",
        "#from transforms as det_transforms\n",
        "\n",
        "#After Data Augmentation\n",
        "custom_transforms = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize(500),\n",
        "    transforms.RandomRotation(360),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(saturation=1),\n",
        "    transforms.ToTensor(),\n",
        "    utils.normalize_transform(),])\n",
        "\n",
        "dataset = Dataset('train', transform=custom_transforms)\n",
        "image, targets = dataset[150]\n",
        "show_labeled_image(image, targets['boxes'])"
      ],
      "metadata": {
        "id": "57cyXxs2BGYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Train_dataset=core.Dataset('train',transform=custom_transforms)#L1\n",
        "Test_dataset = core.Dataset('validation')#L2\n",
        "loader=core.DataLoader(Train_dataset, batch_size=4, shuffle=True)#L3\n",
        "#model = core.Model(['Anger', 'Contempt', 'Disgust','Fear', 'Happy','Sad','Surprise'])#L4\n",
        "#losses = model.fit(loader, Test_dataset, epochs=20, lr_step_size=5, learning_rate=0.001, verbose=True)#L5\n",
        "#plt.plot(losses)#4.03timing\n",
        "#plt.show()\n",
        "#model.save('model_weights.pth')\n",
        "model = core.Model.load('model10_weights.pth', ['Anger','Contempt','Disgust','Fear','Happy','Sad','Surprise'])"
      ],
      "metadata": {
        "id": "3vIGvoy0FlkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#image Prediction\n",
        "image  = utils.read_image('Age_16.1.jpg')\n",
        "predictions = model.predict(image)\n",
        "labels, boxes, scores = predictions\n",
        "show_labeled_image(image, boxes, labels)\n",
        "for label, score in zip(labels, scores):\n",
        "  print(f\"{label}: {score:.2f}\")\n",
        "\n",
        "#print(labels,scores)\n"
      ],
      "metadata": {
        "id": "t7Ep-QCAp7G0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pruning\n",
        "thresh=0.4\n",
        "filtered_indices=np.where(scores>=thresh)\n",
        "filtered_scores=scores[filtered_indices]\n",
        "filtered_boxes=boxes[filtered_indices]\n",
        "num_list = filtered_indices[0].tolist()\n",
        "filtered_labels = [labels[i] for i in num_list]\n",
        "show_labeled_image(image, filtered_boxes, filtered_labels)\n",
        "s1 = np.round(np.array(filtered_scores),2)\n",
        "print(\"Emotions Labels & Score\" )\n",
        "for label, score in zip(filtered_labels, s1):\n",
        "  print(f\"{label}: {score:.2f}\")\n",
        "#print(filtered_labels,s1)\n",
        "#filtered_labels,s1)"
      ],
      "metadata": {
        "id": "jND117-GTj_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels, boxes, scores = predictions\n",
        "\n",
        "labels,scores = np.array(labels),np.array(scores)\n",
        "labels = [labels[i] for i in range(len(labels)) if scores[i]>=0.4]\n",
        "labels = np.array(labels)\n",
        "\n",
        "labels,scores = np.array(labels),np.array(scores)\n",
        "scores = [scores[i] for i in range(len(labels)) if scores[i]>0.4]\n",
        "scores = np.round(np.array(scores),2)\n",
        "print(\"Labels:\",labels,\"IoU:\", scores)\n",
        "\n",
        "\n",
        "emot_high_score= {}\n",
        "emot_values = {}\n",
        "\n",
        "for i in range(len(labels)):\n",
        "    if labels[i] in emot_values:\n",
        "      # Replace with the higher value between the current highest mark and the new mark\n",
        "      emot_values[labels[i]] = max(emot_values[labels[i]], scores[i])\n",
        "    else:\n",
        "      # Keep the current highest mark if the new mark is lower\n",
        "      emot_values[labels[i]] = scores[i]\n",
        "\n",
        "\n",
        "# Print the resulting dictionary with the highest marks\n",
        "print(\"Highest marks after replacement:\", emot_values)\n",
        "emot_values"
      ],
      "metadata": {
        "id": "r8gn8V9_wyYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for label, value in emot_values.items():\n",
        "  print(f\"P_{label}, Value: {value:.2f}\")\n",
        "\n",
        "total_value = np.round(sum(emot_values.values()),2)\n",
        "\n",
        "Learning_Anxiety_Score = 0\n",
        "\n",
        "for label, value in emot_values.items():\n",
        "  # Compute weight for the label\n",
        "  w_label = value / total_value\n",
        "  print(f\"w_{label}, Value: {w_label:.2f}\")\n",
        "  weighted_contribution = value * w_label\n",
        "  Learning_Anxiety_Score += weighted_contribution\n",
        "\n",
        "# Print the final weighted sum\n",
        "print(f\"Learning Anxiety: {Learning_Anxiety_Score:.2f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ttjvwRdWd0fX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label = list(emot_values.keys())\n",
        "values = list(emot_values.values())\n",
        "\n",
        "# Path to the image\n",
        "image_path = 'Age_16.1.jpg'\n",
        "\n",
        "# Load and display the image\n",
        "image = plt.imread(image_path)\n",
        "plt.imshow(image)\n",
        "plt.axis('off')\n",
        "\n",
        "# Overlay scatter plot for Learning Anxiety Score\n",
        "plt.scatter([200], [200], c=[Learning_Anxiety_Score], cmap='cool', s=200, alpha=0.75)\n",
        "\n",
        "\n",
        "# Categorize Learning Anxiety\n",
        "if 0.25 <= Learning_Anxiety_Score < 0.50:\n",
        "  LAnxiety_Label = 'Low Anxiety'\n",
        "elif 0.50 < Learning_Anxiety_Score <= 0.75:\n",
        "  LAnxiety_Label = 'Mild Anxiety'\n",
        "elif Learning_Anxiety_Score == 0.50:\n",
        "  LAnxiety_Label = 'Moderate Anxiety'\n",
        "elif 0.25 < Learning_Anxiety_Score < 0.50:\n",
        "  LAnxiety_Label = 'High Anxiety'\n",
        "else:\n",
        "  LAnxiety_Label = 'Debilitating Anxiety'\n",
        "\n",
        "# Annotate with emotion labels\n",
        "for i, (emotion, value) in enumerate(emot_values.items()):\n",
        "    x = 200 + i * 150  # X position\n",
        "    y = 200 + i * 150  # Y position\n",
        "    plt.annotate(f'{label}:{LAnxiety_Label}: {Learning_Anxiety_Score:.2f}', (x, y), fontsize=10, color='black', ha='center', va='center')\n",
        "\n",
        "# Add color bar legend\n",
        "scatter = plt.scatter([100], [100], c=[Learning_Anxiety_Score], cmap='cool', s=200)\n",
        "plt.colorbar(scatter, label='Learning Anxiety Value')\n",
        "\n",
        "# Print Learning Anxiety details\n",
        "#print(\"Highest marks after replacement:\", emot_values)\n",
        "\n",
        "\n",
        "\n",
        "plt.title(\n",
        "    'Visualization: Understanding Emotional Impact \\n Level of Learning Anxiety',\n",
        "    fontsize=16,\n",
        "    fontweight='bold',\n",
        "    color='#0D47A1',  # Greenish color for the title\n",
        "    loc='center',  # Center alignment\n",
        "    pad=20,  # Extra padding above the title\n",
        ")\n",
        "\n",
        "# Show plot\n",
        "plt.show()\n",
        "#print(\"Learning Anxiety\" , f\"{LAnxiety_Label} : {round(Learning_Anxiety_Score * 100)}%\")\n",
        "# Aesthetic bold output with emojis\n",
        "print(\"\\033[1m✨ Learning Anxiety ✨\\033[0m\")\n",
        "print(f\"🌀 Status: \\033[1;95m{LAnxiety_Label}\\033[0m , 📊 Score: \\033[1;35m{round(Learning_Anxiety_Score * 100)}%\\033[0m\")\n",
        "#print(f\"Learning Anxiety: {Learning_Anxiety_Score*100:.2f}%\")"
      ],
      "metadata": {
        "id": "5eWJBDSkmsZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define a function for processing frames and calculating learning anxiety\n",
        "def process_frame(frame, model, thresh=0.3):\n",
        "    predictions = model.predict(frame)\n",
        "    labels, boxes, scores = predictions\n",
        "\n",
        "    # Prune based on the threshold\n",
        "    filtered_indices = np.where(scores >= thresh)\n",
        "    filtered_scores = scores[filtered_indices]\n",
        "    filtered_boxes = boxes[filtered_indices]\n",
        "    filtered_labels = [labels[i] for i in filtered_indices[0].tolist()]\n",
        "\n",
        "    # Calculate the emotional values\n",
        "    emot_values = {}\n",
        "    for i in range(len(filtered_labels)):\n",
        "        label = filtered_labels[i]\n",
        "        score = filtered_scores[i]\n",
        "        emot_values[label] = max(emot_values.get(label, 0), score)\n",
        "\n",
        "    # Calculate total emotional weight and learning anxiety score\n",
        "    total_value = sum(emot_values.values())\n",
        "    if total_value > 0:\n",
        "        Learning_Anxiety_Score = sum(\n",
        "            (value / total_value) * value for value in emot_values.values()\n",
        "        )\n",
        "    else:\n",
        "        Learning_Anxiety_Score = 0\n",
        "\n",
        "    return frame, emot_values, Learning_Anxiety_Score\n",
        "\n",
        "# Categorize Learning Anxiety\n",
        "def categorize_anxiety(score):\n",
        "    if 0.25 <= score < 0.50:\n",
        "        return 'Low Anxiety'\n",
        "    elif 0.50 < score <= 0.75:\n",
        "        return 'Mild Anxiety'\n",
        "    elif score == 0.50:\n",
        "        return 'Moderate Anxiety'\n",
        "    elif 0.25 < score < 0.50:\n",
        "        return 'High Anxiety'\n",
        "    else:\n",
        "        return 'Debilitating Anxiety'\n",
        "\n",
        "# Video Input and Output Setup\n",
        "video_input = 'Age_16.mp4'  # Path to input video\n",
        "video_output = 'LA16.1.mp4'\n",
        "cap = cv2.VideoCapture(video_input)\n",
        "\n",
        "# Get video properties\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(video_output, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "# Load the emotion model (replace with your model loading code)\n",
        "# model = load_your_model()\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Process frame to find emotions and calculate anxiety\n",
        "    processed_frame, emot_values, Learning_Anxiety_Score = process_frame(frame, model)\n",
        "\n",
        "    # Categorize anxiety\n",
        "    LAnxiety_Label = categorize_anxiety(Learning_Anxiety_Score)\n",
        "\n",
        "    # Add annotations to the frame\n",
        "    y_start = 50\n",
        "    cv2.putText(processed_frame, f\"Learning Anxiety: {Learning_Anxiety_Score:.2f}\",\n",
        "                (50, y_start), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
        "    cv2.putText(processed_frame, f\"Category: {LAnxiety_Label}\",\n",
        "                (50, y_start + 40), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
        "\n",
        "    # Annotate emotions\n",
        "    for i, (emotion, value) in enumerate(emot_values.items()):\n",
        "        cv2.putText(processed_frame, f\"{emotion}: {value:.2f}\",\n",
        "                    (50, y_start + 80 + i * 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
        "\n",
        "    # Overlay dynamic marker\n",
        "    x, y = frame_width // 2, frame_height // 2  # Center position\n",
        "    cv2.circle(processed_frame, (x, y), 30, (255, 0, 255), -1)  # Marker\n",
        "    cv2.putText(processed_frame, f\"{Learning_Anxiety_Score:.2f}\",\n",
        "                (x - 20, y + 5), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n",
        "\n",
        "    # Write processed frame to output\n",
        "    out.write(processed_frame)\n",
        "\n",
        "# Release resources\n",
        "cap.release()\n",
        "out.release()\n",
        "print(f\"Processed video saved as {video_output}\")\n"
      ],
      "metadata": {
        "id": "-oTmXssu3S1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "92L7sJzgOcwk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}